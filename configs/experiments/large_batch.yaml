# Large batch training configuration
_base_: "../base_config.yaml"

experiment:
  name: "ct-clip-large-batch"
  tags: ["large-batch", "ctclip"]
  notes: "Implement large batch training using gradient accumulation"

data:
  batch_size: 32  # physical batch size

training:
  num_epochs: 100
  learning_rate: 5e-6  # large batch requires LR adjustment
  gradient_accumulation_steps: 4  # effective batch size = 32 * 4 = 128
  warmup_steps: 2000  # longer warmup

logging:
  wandb:
    group: "large-batch-exp"
