# CT-CLIP Training - WebDataset Configuration Example
# This configuration uses WebDataset format for optimized I/O performance

# Experiment information
experiment:
  name: "ct-clip-webdataset"
  tags: ["webdataset", "optimized-io", "float16"]
  seed: 2025
  notes: "WebDataset format with float16 for reduced storage and faster I/O"

# Data configuration - WebDataset format
data:
  # Dataset format
  dataset_format: "webdataset"  # Use WebDataset format

  # WebDataset shard paths
  # Format: "path/to/shards/shard-{000000..NNNNNN}.tar"
  # Example: If you have 400 training shards (shard-000000.tar to shard-000399.tar)
  webdataset_shards_train: "/path/to/webdataset/train/shard-{000000..000399}.tar"
  webdataset_shards_val: "/path/to/webdataset/val/shard-{000000..000049}.tar"

  # WebDataset specific settings
  shuffle_buffer_size: 1000  # Larger buffer = better shuffling but more memory

  # DataLoader configuration
  batch_size: 32
  num_workers: 8  # Can use fewer workers with WebDataset due to better I/O
  prefetch_factor: 4  # Increase for better throughput
  persistent_workers: true  # Keep workers alive
  use_embedding: false

  # Legacy NPZ paths (not used when dataset_format="webdataset", but kept for reference)
  train_dir: ""
  valid_dir: ""
  reports_train: ""
  reports_valid: ""
  train_meta: ""
  valid_meta: ""
  labels_train: ""
  labels_valid: ""

# Model configuration (same as base)
model:
  image_encoder:
    type: "CTViT"
    dim: 512
    codebook_size: 8192
    image_size: 480
    patch_size: 20
    temporal_patch_size: 10
    spatial_depth: 4
    temporal_depth: 4
    dim_head: 32
    heads: 8

  text_encoder:
    type: "BiomedBERT"
    path: "/orange/xujie/liang.renjie/DATA/weights/BiomedVLP-CXR-BERT-specialized"
    do_lower_case: true

  clip:
    dim_image: 294912
    dim_text: 768
    dim_latent: 512
    extra_latent_projection: false
    use_mlm: false
    downsample_image_embeds: false
    use_all_token_embeds: false

# Training configuration
training:
  max_steps: 10000
  learning_rate: 1.25e-6
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  max_grad_norm: 0.5
  save_every_n_steps: 1000
  warmup_steps: 1000
  min_lr_ratio: 0.01

# Validation configuration
validation:
  eval_every_n_steps: 1000
  eval_samples: 200
  metrics: ["auroc", "auprc", "f1", "precision", "recall"]
  use_bootstrap: false
  threshold: 0.5

# Checkpoint configuration
checkpoint:
  save_dir: "./saves"
  keep_last_n: 3
  save_best: true
  best_metric: "auroc"
  best_metric_mode: "max"

# Logging configuration
logging:
  use_wandb: true
  use_tensorboard: false
  use_console: true
  wandb:
    project: "ct-clip"
    entity: null
    mode: "online"
    group: "webdataset-experiments"
    job_type: "train"
  tensorboard:
    log_dir: "./runs"
  log_every_n_steps: 10

# Device configuration
device:
  use_cuda: true
  cuda_device: 0
