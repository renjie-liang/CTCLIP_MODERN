# CT-CLIP Training - Base Configuration
# 所有实验的基础配置模板

# 实验信息
experiment:
  name: "ct-clip-baseline"
  tags: ["baseline", "ctclip"]
  seed: 2025
  notes: "Step-based training configuration"

# 数据配置
data:
  # WebDataset format paths (using float16 for optimized I/O)
  webdataset_shards_train: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/train_fixed_webdataset/shard-{000000..000314}.tar"
  webdataset_shards_val: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/valid_fixed_webdataset/shard-{000000..000059}.tar"
  shuffle_buffer_size: 1000  # Buffer size for shuffling in WebDataset mode

  # Legacy NPZ paths (kept for reference - data deleted)
  # train_dir: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/train_fixed_npz"
  # valid_dir: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/valid_fixed_npz"

  reports_train: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/radiology_text_reports/train_reports.csv"
  reports_valid: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/radiology_text_reports/validation_reports.csv"

  train_meta: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/metadata/train_metadata.csv"
  valid_meta: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/metadata/validation_metadata.csv"

  labels_train: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/multi_abnormality_labels/train_predicted_labels.csv"
  labels_valid: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/multi_abnormality_labels/valid_predicted_labels.csv"

  # DataLoader配置
  batch_size: 8
  num_workers: 24
  prefetch_factor: 2  # Number of batches to prefetch per worker
  persistent_workers: true  # Keep worker processes alive between epochs
  use_embedding: false
  embedding_dir: "/orange/xujie/liang.renjie/DATA/dataset/CT-RATE/dataset/embedding/author_ckpt"

# 模型配置
model:
  # Image Encoder (CTViT)
  image_encoder:
    type: "CTViT"
    dim: 512
    codebook_size: 8192
    image_size: 480
    patch_size: 20
    temporal_patch_size: 10
    spatial_depth: 4
    temporal_depth: 4
    dim_head: 32
    heads: 8

  # Text Encoder (BiomedBERT)
  text_encoder:
    type: "BiomedBERT"
    path: "/orange/xujie/liang.renjie/DATA/weights/BiomedVLP-CXR-BERT-specialized"
    do_lower_case: true

  # CLIP配置
  clip:
    dim_image: 294912
    dim_text: 768
    dim_latent: 512
    extra_latent_projection: false
    use_mlm: false
    downsample_image_embeds: false
    use_all_token_embeds: false

# Training configuration (step-based)
training:
  max_steps: 10000
  learning_rate: 1.25e-6
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  max_grad_norm: 0.5
  save_every_n_steps: 1000

  # Learning rate scheduling
  warmup_steps: 1000
  min_lr_ratio: 0.01  # Minimum lr as ratio of initial lr

# Validation configuration
validation:
  eval_every_n_steps: 1000
  eval_samples: 200  # Validate on 200 samples for speed (null = all samples)
  metrics: ["auroc", "auprc", "f1", "precision", "recall"]
  use_bootstrap: false  # False for training, True for inference
  threshold: 0.5

# Checkpoint configuration
checkpoint:
  save_dir: "./saves"
  keep_last_n: 3
  save_best: true
  best_metric: "auroc"
  best_metric_mode: "max"

# Logging configuration
logging:
  use_wandb: true
  use_tensorboard: false
  use_console: true

  wandb:
    project: "ct-clip"
    entity: null
    mode: "online"
    group: null
    job_type: "train"

  tensorboard:
    log_dir: "./runs"

  log_every_n_steps: 10

# Device configuration
device:
  use_cuda: true
  cuda_device: 0
